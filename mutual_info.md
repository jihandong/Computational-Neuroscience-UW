# Mutual Infomation

Entropy: measure the quantity of *uncertainty*, the amount of infomation.

Mutual Infomation:

$$
\begin{align*}
I(S,R) &= H(S) + H(R) - H(SR) \\
&= H(S) - H(S|R) \\
&= H(R) - H(R|S) \\
&= D_{KL}[P(R,S), P(R)*P(S)]
\end{align*}
$$

For the 3rd line, we regard $H(R|S)$ as **noise entropy**, because it excludes the influence of stimulus, so $H(R|S)$ only represent *the uncertainty of response itself, also the noises generated by cell itself*.
